# Optimization



### Bayesian optimzation

즉, 목적 함수(탐색대상함수)와 해당 하이퍼파라미터 쌍(pair)을 대상으로 Surrogate Model(대체 모델) 을 만들고, 평가를 통해 순차적으로 업데이트해 가면서 최적의 하이퍼파라미터 조합을 탐색하는 방법.



* **필수 요소**
  * 먼저 **Surrogant Model**은, 현재까지 조사된 입력값-함숫값 점들 (x1,f(x1)),...,(xt,f(xt))(x1,f(x1)),...,(xt,f(xt))를 바탕으로, **미지의 목적 함수의 형태에 대한 확률적인 추정을 수행하는 모델**을 지칭합니다. 즉, **함수에 대한 확률 분포**를 나타낸다. 주로 Gaussian Process(GP)가 사용된다. 
  * 그리고 **Acquisition Function**은, 목적 함수에 대한 현재까지의 확률적 추정 결과를 바탕으로, ‘최적 입력값을 찾는 데 있어 가장 유용할 만한’ **다음 입력값 후보를 추천해 주는 함수** 지칭합니다. Acquisition Function으로 가장 많이 사용되는 함수는 exploitation, exploration 전략 모두를 사용하는 **Expected Improvement** 입니다. 이는 exploitation과 exploration 전략 두 가지를 활용합니다.
    1. **exploitation**
       - 현재까지 조사된 점들 중 **함수값이 최대인 점** 근방을 다음 차례에 시도합니다.
       - 함수값이 가장 큰 점 근방에서 실제 최적 입력값 `x`를 찾을 가능성이 높기 때문입니다.
    2. **exploration**
       - 현재까지 추정된 목적 함수 상에서 **표준편차가 최대인 점 근방**을 다음 차례에 시도합니다.
       - 불확실한 영역에 최적 입력값 `x`이 존재할 가능성이 높기 때문입니다.



- **자세한 수행 과정**
  1. 입력값, 목적 함수 및 그 외 설정값들을 정의합니다.
     - 입력값 x : 여러가지 hyperparameter
     - 목적 함수 f(x) : 설정한 입력값을 적용하여 학습한 딥러닝 모델의 검증 데이터셋에 대한 성능 결과 수치(e.g. 정확도)
     - 입력값 의 탐색 대상 구간 : (a,b)
     - 맨 처음에 조사할 입력값-함숫값 점들의 갯수 : n
     - 맨 마지막 차례까지 조사할 입력값-함숫값 점들의 최대 갯수 : N
  2. 설정한 탐색 대상 구간 (a,b) 내에서 처음 n 개의 입력값들을 랜덤하게 샘플링하여 선택합니다.
  3. 선택한 n 개의 입력값 x1,x2,...,xn 을 각각 학습률 값으로 설정하여 딥러닝 모델을 학습한 뒤, 검증 데이터셋을 사용하여 학습이 완료된 모델의 성능 결과 수치를 계산합니다. 이들을 각각 함숫값 f(x1),f(x2),...,f(xn) 으로 간주합니다.
  4. 입력값-함숫값 점들의 모음 (x1,f(x1)),(x2,f(x2)),...,(xn,f(xn)) 에 대하여 Surrogant Model로 확률적 추정을 수행합니다.
  5. 조사된 입력값-함숫값 점들이 총 N 개에 도달할 때까지, 아래의 과정을 t=n,n+1,...,N−1 에 대하여 반복적으로 수행합니다.
     - 기존 입력값-함숫값 점들의 모음 (x1,f(x1)),(x2,f(x2)),...,(xt,f(xt)) 에 대한 Surrogant Model의 확률적 추정 결과를 바탕으로, 입력값 구간 (a,b) 내에서의 EI의 값을 계산하고, 그 값이 가장 큰 점을 다음 입력값 후보 xt+1 로 선정합니다.
     - 다음 입력값 후보 xt+1 를 학습률 값으로 설정하여 딥러닝 모델을 학습한 뒤, 검증 데이터셋을 사용하여 학습이 완료된 모델의 성능 결과 수치를 계산하고 이를 f(xt+1) 값으로 간주합니다.
     - 새로운 점 (xt+1,f(xt+1)) 을 기존 입력값-함숫값 점들의 모음에 추가하고, 갱신된 점들의 모음에 대하여 Surrogant Model로 확률적 추정을 다시 수행합니다.
  6. 총 N 개의 입력값-함숫값 점들에 대하여 확률적으로 추정된 목적 함수 결과물을 바탕으로, EI 최대로 만드는 최적해를 최종 선택합니다. 추후 해당값을 학습률로 사용하여 딥러닝 모델을 학습하면, 일반화 성능이 극대화된 모델을 얻을 수 있습니다.

https://wooono.tistory.com/102

https://jihyun22.github.io/automl/Bayesian-Optimization/

